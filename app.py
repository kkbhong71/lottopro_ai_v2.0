from flask import Flask, render_template, request, jsonify, session, send_file
import os
import random
import numpy as np
from datetime import datetime, timedelta
import json
import base64
from collections import Counter, defaultdict
import hashlib
import uuid
import logging
import traceback
import re
import math
from io import BytesIO
import time
import concurrent.futures
from functools import wraps
import signal

# ğŸ†• ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ìºì‹± ì‹œìŠ¤í…œ import
try:
    from monitoring.performance_monitor import init_monitoring, monitor_performance
    MONITORING_AVAILABLE = True
    print("[SYSTEM] âœ… ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    MONITORING_AVAILABLE = False
    print(f"[WARNING] âŒ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {e}")

try:
    from utils.cache_manager import init_cache_system, cached
    CACHE_AVAILABLE = True
    print("[SYSTEM] âœ… ìºì‹œ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    CACHE_AVAILABLE = False
    print(f"[WARNING] âŒ ìºì‹œ ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {e}")

# Optional imports with fallbacks
try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False

try:
    import qrcode
    from PIL import Image
    QR_AVAILABLE = True
except ImportError:
    QR_AVAILABLE = False

try:
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.preprocessing import StandardScaler
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False

# Flask ì•± ì´ˆê¸°í™”
app = Flask(__name__)

# í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ ì„¤ì • (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)
app.config['SECRET_KEY'] = os.environ.get('SECRET_KEY', 'lottopro-ai-v2-enhanced-2024')
app.config['DEBUG'] = os.environ.get('DEBUG', 'False').lower() == 'true'
app.config['PERMANENT_SESSION_LIFETIME'] = timedelta(days=30)

# ë³´ì•ˆ ì„¤ì •
if not app.config['DEBUG']:
    app.config['SESSION_COOKIE_SECURE'] = False  # HTTPì—ì„œë„ ì‘ë™í•˜ë„ë¡ ì„¤ì •
    app.config['SESSION_COOKIE_HTTPONLY'] = True
    app.config['SESSION_COOKIE_SAMESITE'] = 'Lax'

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
app.logger.setLevel(logging.INFO)

# ê¸€ë¡œë²Œ ë³€ìˆ˜
sample_data = None
user_saved_numbers = {}
cached_stats = {}
request_counts = defaultdict(int)
error_counts = defaultdict(int)
performance_metrics = {
    'total_requests': 0,
    'total_errors': 0,
    'avg_response_time': 0,
    'start_time': datetime.now()
}

# ğŸ†• ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ (ì´ˆê¸°í™” í›„ ì„¤ì •ë¨)
monitor = None
cache_manager = None

# íƒ€ì„ì•„ì›ƒ ë° ì—ëŸ¬ ì²˜ë¦¬ ë°ì½”ë ˆì´í„°
def timeout_handler(timeout_seconds=10):
    """ìš”ì²­ íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬ ë°ì½”ë ˆì´í„°"""
    def decorator(f):
        @wraps(f)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            
            def timeout_error(signum, frame):
                raise TimeoutError(f"Request timed out after {timeout_seconds} seconds")
            
            try:
                # íƒ€ì„ì•„ì›ƒ ì‹œê·¸ë„ ì„¤ì • (Unix ê³„ì—´ì—ì„œë§Œ ë™ì‘)
                if hasattr(signal, 'SIGALRM'):
                    old_handler = signal.signal(signal.SIGALRM, timeout_error)
                    signal.alarm(timeout_seconds)
                
                # ThreadPoolExecutorë¥¼ ì‚¬ìš©í•œ íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬
                with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                    future = executor.submit(f, *args, **kwargs)
                    try:
                        result = future.result(timeout=timeout_seconds)
                        
                        # ì„±ê³µ ì‹œ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                        response_time = time.time() - start_time
                        update_performance_metrics(response_time, success=True)
                        
                        return result
                    except concurrent.futures.TimeoutError:
                        # íƒ€ì„ì•„ì›ƒ ì—ëŸ¬ ì²˜ë¦¬
                        update_performance_metrics(time.time() - start_time, success=False)
                        safe_log(f"Request timeout in {f.__name__}: {timeout_seconds}s")
                        return jsonify({
                            'success': False,
                            'error': True,
                            'message': 'ìš”ì²­ ì²˜ë¦¬ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.',
                            'error_type': 'timeout',
                            'timeout_duration': timeout_seconds
                        }), 408
            except Exception as e:
                # ì¼ë°˜ ì—ëŸ¬ ì²˜ë¦¬
                response_time = time.time() - start_time
                update_performance_metrics(response_time, success=False)
                safe_log(f"Error in {f.__name__}: {str(e)}")
                return handle_api_error(e)
            finally:
                # ì‹œê·¸ë„ ë³µì›
                if hasattr(signal, 'SIGALRM'):
                    signal.alarm(0)
                    if 'old_handler' in locals():
                        signal.signal(signal.SIGALRM, old_handler)
                        
        return wrapper
    return decorator

def rate_limiter(max_requests=100, time_window=3600):
    """ìš”ì²­ ì œí•œ ë°ì½”ë ˆì´í„° (ì‹œê°„ë‹¹ ìµœëŒ€ ìš”ì²­ ìˆ˜)"""
    def decorator(f):
        @wraps(f)
        def wrapper(*args, **kwargs):
            client_ip = request.environ.get('REMOTE_ADDR', 'unknown')
            current_time = time.time()
            
            # í´ë¼ì´ì–¸íŠ¸ë³„ ìš”ì²­ ê¸°ë¡ ì´ˆê¸°í™”
            if not hasattr(wrapper, 'requests'):
                wrapper.requests = defaultdict(list)
            
            # ì‹œê°„ ìœˆë„ìš°ë¥¼ ë²—ì–´ë‚œ ìš”ì²­ ê¸°ë¡ ì œê±°
            wrapper.requests[client_ip] = [
                req_time for req_time in wrapper.requests[client_ip]
                if current_time - req_time < time_window
            ]
            
            # ìš”ì²­ ì œí•œ í™•ì¸
            if len(wrapper.requests[client_ip]) >= max_requests:
                safe_log(f"Rate limit exceeded for IP: {client_ip}")
                return jsonify({
                    'success': False,
                    'error': True,
                    'message': f'ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. {time_window/3600:.1f}ì‹œê°„ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.',
                    'error_type': 'rate_limit',
                    'retry_after': time_window
                }), 429
            
            # í˜„ì¬ ìš”ì²­ ê¸°ë¡
            wrapper.requests[client_ip].append(current_time)
            
            return f(*args, **kwargs)
            
        return wrapper
    return decorator

def handle_api_error(error):
    """API ì—ëŸ¬ í†µí•© ì²˜ë¦¬"""
    error_id = str(uuid.uuid4())[:8]
    
    if isinstance(error, TimeoutError):
        return jsonify({
            'success': False,
            'error': True,
            'message': 'ìš”ì²­ ì²˜ë¦¬ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.',
            'error_type': 'timeout',
            'error_id': error_id
        }), 408
    elif isinstance(error, ValueError):
        return jsonify({
            'success': False,
            'error': True,
            'message': 'ì˜ëª»ëœ ì…ë ¥ ê°’ì…ë‹ˆë‹¤.',
            'error_type': 'validation',
            'error_id': error_id
        }), 400
    elif isinstance(error, ConnectionError):
        return jsonify({
            'success': False,
            'error': True,
            'message': 'ì™¸ë¶€ ì„œë¹„ìŠ¤ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
            'error_type': 'connection',
            'error_id': error_id
        }), 503
    else:
        # ì¼ë°˜ì ì¸ ì„œë²„ ì—ëŸ¬
        safe_log(f"Unhandled error [{error_id}]: {str(error)}")
        return jsonify({
            'success': False,
            'error': True,
            'message': 'ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
            'error_type': 'internal',
            'error_id': error_id
        }), 500

def update_performance_metrics(response_time, success=True):
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
    performance_metrics['total_requests'] += 1
    
    if not success:
        performance_metrics['total_errors'] += 1
    
    # í‰ê·  ì‘ë‹µ ì‹œê°„ ì—…ë°ì´íŠ¸
    total_requests = performance_metrics['total_requests']
    current_avg = performance_metrics['avg_response_time']
    performance_metrics['avg_response_time'] = (
        (current_avg * (total_requests - 1) + response_time) / total_requests
    )

def validate_lotto_numbers(numbers):
    """ë¡œë˜ ë²ˆí˜¸ ìœ íš¨ì„± ê²€ì‚¬"""
    if not isinstance(numbers, list):
        return False, "ë²ˆí˜¸ëŠ” ë¦¬ìŠ¤íŠ¸ í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤."
    
    if len(numbers) > 6:
        return False, "ë²ˆí˜¸ëŠ” ìµœëŒ€ 6ê°œê¹Œì§€ ì…ë ¥ ê°€ëŠ¥í•©ë‹ˆë‹¤."
    
    for num in numbers:
        try:
            n = int(num)
            if n < 1 or n > 45:
                return False, f"ë²ˆí˜¸ëŠ” 1-45 ë²”ìœ„ì—¬ì•¼ í•©ë‹ˆë‹¤. (ì…ë ¥: {n})"
        except (ValueError, TypeError):
            return False, f"ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì…ë ¥: {num})"
    
    if len(set(numbers)) != len(numbers):
        return False, "ì¤‘ë³µëœ ë²ˆí˜¸ê°€ ìˆìŠµë‹ˆë‹¤."
    
    return True, "ìœ íš¨í•œ ë²ˆí˜¸ì…ë‹ˆë‹¤."

def safe_log(message, level='info'):
    """ì•ˆì „í•œ ë¡œê¹… (ì—ëŸ¬ ë°©ì§€)"""
    try:
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_message = f"[{timestamp}] [LottoPro-AI] {message}"
        
        if level == 'error':
            app.logger.error(log_message)
        elif level == 'warning':
            app.logger.warning(log_message)
        else:
            app.logger.info(log_message)
            
        print(log_message)
    except Exception as e:
        print(f"[LottoPro-AI] Logging error: {str(e)} | Original message: {message}")

@app.after_request
def add_security_headers(response):
    """ë³´ì•ˆ í—¤ë” ë° ì„±ëŠ¥ í—¤ë” ì¶”ê°€"""
    # ë³´ì•ˆ í—¤ë”
    response.headers['X-Content-Type-Options'] = 'nosniff'
    response.headers['X-Frame-Options'] = 'DENY'
    response.headers['X-XSS-Protection'] = '1; mode=block'
    response.headers['Referrer-Policy'] = 'strict-origin-when-cross-origin'
    
    # ì„±ëŠ¥ í—¤ë”
    response.headers['Cache-Control'] = 'public, max-age=300' if request.endpoint != 'predict' else 'no-cache'
    
    # CORS í—¤ë” (í•„ìš”ì‹œ)
    response.headers['Access-Control-Allow-Origin'] = '*'
    response.headers['Access-Control-Allow-Methods'] = 'GET, POST, OPTIONS'
    response.headers['Access-Control-Allow-Headers'] = 'Content-Type'
    
    return response

# ì—ëŸ¬ í•¸ë“¤ëŸ¬ë“¤ (ê¸°ì¡´ê³¼ ë™ì¼)
@app.errorhandler(404)
def not_found(error):
    """404 ì—ëŸ¬ ì²˜ë¦¬"""
    try:
        if request.is_json or '/api/' in request.path:
            return jsonify({
                'success': False,
                'error': True,
                'message': 'API ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                'error_type': 'not_found'
            }), 404
        else:
            return render_template('index.html'), 404
    except Exception as e:
        safe_log(f"404 handler error: {str(e)}", 'error')
        return jsonify({'error': 'Not Found'}), 404

@app.errorhandler(500)
def internal_error(error):
    """500 ì—ëŸ¬ ì²˜ë¦¬"""
    error_id = str(uuid.uuid4())[:8]
    safe_log(f"500 ì—ëŸ¬ ë°œìƒ [{error_id}]: {error}", 'error')
    
    if request.is_json or '/api/' in request.path:
        return jsonify({
            'success': False,
            'error': True,
            'message': 'ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
            'error_type': 'internal',
            'error_id': error_id
        }), 500
    else:
        return render_template('error.html', error_id=error_id), 500

@app.errorhandler(413)
def request_entity_too_large(error):
    """413 ìš”ì²­ í¬ê¸° ì´ˆê³¼ ì—ëŸ¬ ì²˜ë¦¬"""
    return jsonify({
        'success': False,
        'error': True,
        'message': 'ìš”ì²­ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤.',
        'error_type': 'payload_too_large'
    }), 413

@app.errorhandler(429)
def too_many_requests(error):
    """429 ìš”ì²­ ê³¼ë‹¤ ì—ëŸ¬ ì²˜ë¦¬"""
    return jsonify({
        'success': False,
        'error': True,
        'message': 'ìš”ì²­ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.',
        'error_type': 'too_many_requests'
    }), 429

# AI ëª¨ë¸ ì •ë³´
AI_MODELS_INFO = {
    'frequency': {
        'name': 'ë¹ˆë„ë¶„ì„ ëª¨ë¸',
        'description': 'ê³¼ê±° ë‹¹ì²¨ë²ˆí˜¸ ì¶œí˜„ ë¹ˆë„ë¥¼ í†µê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ê°€ì¤‘ í™•ë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤.',
        'algorithm': 'ê°€ì¤‘ í™•ë¥  ë¶„í¬',
        'accuracy_rate': 19.2,
        'data_source': 'ìµœê·¼ 200íšŒì°¨',
        'update_frequency': 'ë§¤ì£¼ í† ìš”ì¼'
    },
    'trend': {
        'name': 'íŠ¸ë Œë“œë¶„ì„ ëª¨ë¸',
        'description': 'ìµœê·¼ ë‹¹ì²¨ íŒ¨í„´ê³¼ ì‹œê°„ì  íŠ¸ë Œë“œë¥¼ ë¶„ì„í•˜ì—¬ ë³€í™”í•˜ëŠ” íŒ¨í„´ì„ ë°˜ì˜í•©ë‹ˆë‹¤.',
        'algorithm': 'ì´ë™í‰ê·  + ì¶”ì„¸ë¶„ì„',
        'accuracy_rate': 17.8,
        'data_source': 'ìµœê·¼ 50íšŒì°¨',
        'update_frequency': 'ë§¤ì£¼ í† ìš”ì¼'
    },
    'pattern': {
        'name': 'íŒ¨í„´ë¶„ì„ ëª¨ë¸',
        'description': 'ë²ˆí˜¸ ì¡°í•© íŒ¨í„´ê³¼ ìˆ˜í•™ì  ê´€ê³„ë¥¼ ë¶„ì„í•˜ì—¬ ë³µí•©ì ì¸ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.',
        'algorithm': 'ì¡°í•©ë¡  + í™•ë¥ ë¡ ',
        'accuracy_rate': 16.4,
        'data_source': 'í™€ì§, ê³ ì €, í•©ê³„',
        'update_frequency': 'ë§¤ì£¼ í† ìš”ì¼'
    },
    'statistical': {
        'name': 'í†µê³„ë¶„ì„ ëª¨ë¸',
        'description': 'ê³ ê¸‰ í†µê³„ ê¸°ë²•ê³¼ í™•ë¥  ì´ë¡ ì„ ì ìš©í•œ ìˆ˜í•™ì  ì˜ˆì¸¡ ëª¨ë¸ì…ë‹ˆë‹¤.',
        'algorithm': 'ë² ì´ì¦ˆ ì¶”ë¡ ',
        'accuracy_rate': 20.1,
        'data_source': 'ë‹¤í•­ë¶„í¬',
        'update_frequency': 'ë§¤ì£¼ í† ìš”ì¼'
    },
    'ml': {
        'name': 'ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸',
        'description': 'ë”¥ëŸ¬ë‹ ì‹ ê²½ë§ê³¼ AI ì•Œê³ ë¦¬ì¦˜ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ê³ ë„í™”ëœ ì˜ˆì¸¡ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.',
        'algorithm': '3ì¸µ DNN',
        'accuracy_rate': 18.9,
        'data_source': '1185íšŒì°¨',
        'update_frequency': 'ë§¤ì£¼ í† ìš”ì¼'
    }
}

# ì˜ˆì¸¡ íˆìŠ¤í† ë¦¬
PREDICTION_HISTORY = [
    {
        'round': 1185,
        'date': '2025.08.17',
        'winning_numbers': [7, 13, 21, 28, 34, 42],
        'bonus_number': 15,
        'ai_predictions': {
            'combined': [7, 15, 21, 29, 34, 45],
            'frequency': [7, 12, 21, 28, 35, 42],
            'trend': [8, 15, 22, 29, 34, 44],
            'pattern': [6, 13, 20, 27, 33, 45],
            'statistical': [7, 14, 21, 30, 34, 43],
            'ml': [9, 16, 23, 28, 36, 41]
        },
        'matches': {
            'combined': 3,
            'frequency': 4,
            'trend': 2,
            'pattern': 2,
            'statistical': 3,
            'ml': 2
        }
    }
]

# ë¡œë˜ íŒë§¤ì  ë°ì´í„°
LOTTERY_STORES = [
    {"name": "ë™ëŒ€ë¬¸ ë³µê¶Œë°©", "address": "ì„œìš¸ì‹œ ë™ëŒ€ë¬¸êµ¬ ì¥í•œë¡œ 195", "region": "ì„œìš¸", "district": "ë™ëŒ€ë¬¸êµ¬", "lat": 37.5745, "lng": 127.0098, "phone": "02-1234-5678", "first_wins": 15, "business_hours": "06:00-24:00"},
    {"name": "ê°•ë‚¨ ë¡œë˜íƒ€ìš´", "address": "ì„œìš¸ì‹œ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œ 152", "region": "ì„œìš¸", "district": "ê°•ë‚¨êµ¬", "lat": 37.4979, "lng": 127.0276, "phone": "02-2345-6789", "first_wins": 23, "business_hours": "07:00-23:00"},
    {"name": "í‰íƒì—­ ë¡œë˜ì„¼í„°", "address": "ê²½ê¸°ë„ í‰íƒì‹œ í‰íƒë™ 856-1", "region": "í‰íƒ", "district": "í‰íƒì‹œ", "lat": 36.9922, "lng": 127.0890, "phone": "031-1234-5678", "first_wins": 5, "business_hours": "06:00-22:00"},
    {"name": "ì•ˆì •ë¦¬ í–‰ìš´ë³µê¶Œ", "address": "ê²½ê¸°ë„ í‰íƒì‹œ ì•ˆì •ë™ 123-45", "region": "í‰íƒ", "district": "í‰íƒì‹œ", "lat": 36.9856, "lng": 127.0825, "phone": "031-2345-6789", "first_wins": 3, "business_hours": "07:00-21:00"},
    {"name": "ì†¡íƒ„ ì¤‘ì•™ì ", "address": "ê²½ê¸°ë„ í‰íƒì‹œ ì†¡íƒ„ë™ 789-12", "region": "í‰íƒ", "district": "í‰íƒì‹œ", "lat": 36.9675, "lng": 127.0734, "phone": "031-3456-7890", "first_wins": 8, "business_hours": "08:00-20:00"}
]

def generate_sample_data():
    """ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
    try:
        np.random.seed(42)
        data = []
        
        for draw in range(1186, 986, -1):  # 200íšŒì°¨
            numbers = sorted(np.random.choice(range(1, 46), 6, replace=False))
            available = [x for x in range(1, 46) if x not in numbers]
            bonus = np.random.choice(available) if available else 7
            
            base_date = datetime(2025, 8, 28) - timedelta(weeks=(1186-draw))
            
            data.append({
                'íšŒì°¨': draw,
                'ë‹¹ì²¨ë²ˆí˜¸1': int(numbers[0]),
                'ë‹¹ì²¨ë²ˆí˜¸2': int(numbers[1]),
                'ë‹¹ì²¨ë²ˆí˜¸3': int(numbers[2]),
                'ë‹¹ì²¨ë²ˆí˜¸4': int(numbers[3]),
                'ë‹¹ì²¨ë²ˆí˜¸5': int(numbers[4]),
                'ë‹¹ì²¨ë²ˆí˜¸6': int(numbers[5]),
                'ë³´ë„ˆìŠ¤ë²ˆí˜¸': int(bonus),
                'ë‚ ì§œ': base_date.strftime('%Y-%m-%d')
            })
        
        return data
    except Exception as e:
        safe_log(f"ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {str(e)}", 'error')
        return []

# ğŸ†• ìºì‹œ ì ìš©ëœ ë¶„ì„ í•¨ìˆ˜ë“¤
@cached(ttl=600, tags=['statistics']) if CACHE_AVAILABLE else lambda f: f
def calculate_frequency_analysis():
    """ë¹ˆë„ ë¶„ì„ (ìºì‹œ ì ìš©)"""
    if not sample_data:
        return {}
    
    try:
        frequency = Counter()
        for data in sample_data:
            for i in range(1, 7):
                number = data.get(f'ë‹¹ì²¨ë²ˆí˜¸{i}')
                if number:
                    frequency[number] += 1
        return dict(frequency)
    except Exception as e:
        safe_log(f"ë¹ˆë„ ë¶„ì„ ì‹¤íŒ¨: {str(e)}", 'error')
        return {}

@cached(ttl=600, tags=['statistics']) if CACHE_AVAILABLE else lambda f: f
def calculate_carry_over_analysis():
    """ì´ì›”ìˆ˜ ë¶„ì„ (ìºì‹œ ì ìš©)"""
    if not sample_data or len(sample_data) < 2:
        return []
    
    try:
        carry_overs = []
        for i in range(min(len(sample_data) - 1, 20)):
            current_numbers = set()
            prev_numbers = set()
            
            for j in range(1, 7):
                current = sample_data[i].get(f'ë‹¹ì²¨ë²ˆí˜¸{j}')
                prev = sample_data[i+1].get(f'ë‹¹ì²¨ë²ˆí˜¸{j}')
                if current: current_numbers.add(current)
                if prev: prev_numbers.add(prev)
            
            carry_over = current_numbers.intersection(prev_numbers)
            carry_overs.append({
                'round': sample_data[i].get('íšŒì°¨'),
                'carry_over_numbers': sorted(list(carry_over)),
                'count': len(carry_over)
            })
        
        return carry_overs
    except Exception as e:
        safe_log(f"ì´ì›”ìˆ˜ ë¶„ì„ ì‹¤íŒ¨: {str(e)}", 'error')
        return []

@cached(ttl=600, tags=['statistics']) if CACHE_AVAILABLE else lambda f: f
def calculate_companion_analysis():
    """ê¶í•©ìˆ˜ ë¶„ì„ (ìºì‹œ ì ìš©)"""
    if not sample_data:
        return {}
    
    try:
        companion_pairs = Counter()
        for data in sample_data[:50]:  # ìµœê·¼ 50íšŒì°¨ë§Œ
            numbers = []
            for i in range(1, 7):
                num = data.get(f'ë‹¹ì²¨ë²ˆí˜¸{i}')
                if num: numbers.append(num)
            
            for i in range(len(numbers)):
                for j in range(i+1, len(numbers)):
                    pair = tuple(sorted([numbers[i], numbers[j]]))
                    companion_pairs[pair] += 1
        
        return dict(companion_pairs.most_common(10))
    except Exception as e:
        safe_log(f"ê¶í•©ìˆ˜ ë¶„ì„ ì‹¤íŒ¨: {str(e)}", 'error')
        return {}

@cached(ttl=600, tags=['statistics']) if CACHE_AVAILABLE else lambda f: f
def calculate_pattern_analysis():
    """íŒ¨í„´ ë¶„ì„ (ìºì‹œ ì ìš©)"""
    if not sample_data:
        return {}
    
    try:
        patterns = {
            'consecutive_count': [],
            'odd_even_ratio': [],
            'sum_distribution': [],
            'range_distribution': []
        }
        
        for data in sample_data[:30]:
            numbers = []
            for i in range(1, 7):
                num = data.get(f'ë‹¹ì²¨ë²ˆí˜¸{i}')
                if num: numbers.append(num)
            
            if len(numbers) == 6:
                numbers.sort()
                
                consecutive = sum(1 for i in range(len(numbers)-1) if numbers[i+1] - numbers[i] == 1)
                odd_count = sum(1 for n in numbers if n % 2 == 1)
                total_sum = sum(numbers)
                number_range = max(numbers) - min(numbers)
                
                patterns['consecutive_count'].append(consecutive)
                patterns['odd_even_ratio'].append(f"{odd_count}:{6-odd_count}")
                patterns['sum_distribution'].append(total_sum)
                patterns['range_distribution'].append(number_range)
        
        return patterns
    except Exception as e:
        safe_log(f"íŒ¨í„´ ë¶„ì„ ì‹¤íŒ¨: {str(e)}", 'error')
        return {}

def generate_ai_prediction(user_numbers=None, model_type="frequency"):
    """AI ì˜ˆì¸¡ ìƒì„± (ìºì‹œ ì ìš© ê°œì„ ëœ ì—ëŸ¬ ì²˜ë¦¬)"""
    try:
        if user_numbers is None:
            user_numbers = []
        
        # ğŸ†• ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
        if CACHE_AVAILABLE and cache_manager:
            cached_result = cache_manager.get_cached_prediction(user_numbers, model_type)
            if cached_result:
                safe_log(f"ìºì‹œ íˆíŠ¸: {model_type} ì˜ˆì¸¡", 'info')
                return cached_result
        
        # ì…ë ¥ ë²ˆí˜¸ ìœ íš¨ì„± ê²€ì‚¬
        safe_numbers = []
        if isinstance(user_numbers, list):
            for num in user_numbers:
                try:
                    n = int(num)
                    if 1 <= n <= 45 and n not in safe_numbers:
                        safe_numbers.append(n)
                except (ValueError, TypeError):
                    continue
        
        # ì¤‘ë³µ ì œê±° ë° ìµœëŒ€ 6ê°œ ì œí•œ
        safe_numbers = list(set(safe_numbers))[:6]
        
        if model_type == "frequency":
            frequency = calculate_frequency_analysis()
            weights = np.ones(45)
            for num, freq in frequency.items():
                if 1 <= num <= 45:
                    weights[num-1] = freq + 1
        elif model_type == "trend":
            weights = np.ones(45)
            for i, data in enumerate(sample_data[:10]):
                weight_factor = (10 - i) / 10
                for j in range(1, 7):
                    num = data.get(f'ë‹¹ì²¨ë²ˆí˜¸{j}')
                    if num and 1 <= num <= 45:
                        weights[num-1] += weight_factor
        else:
            weights = np.ones(45)
        
        numbers = safe_numbers.copy()
        available_numbers = [i for i in range(1, 46) if i not in numbers]
        
        if len(available_numbers) > 0:
            needed_count = 6 - len(numbers)
            if needed_count > 0:
                available_weights = [weights[i-1] for i in available_numbers]
                if sum(available_weights) > 0:
                    available_weights = np.array(available_weights)
                    available_weights = available_weights / available_weights.sum()
                    
                    selected = np.random.choice(
                        available_numbers, 
                        size=min(needed_count, len(available_numbers)), 
                        replace=False, 
                        p=available_weights
                    )
                    numbers.extend(selected.tolist())
        
        # 6ê°œ ë¯¸ë§Œì¸ ê²½ìš° ëœë¤ìœ¼ë¡œ ì±„ìš°ê¸°
        while len(numbers) < 6:
            new_num = random.randint(1, 45)
            if new_num not in numbers:
                numbers.append(new_num)
        
        result = sorted(numbers[:6])
        
        # ğŸ†• ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥ (5ë¶„)
        if CACHE_AVAILABLE and cache_manager:
            cache_manager.cache_prediction(user_numbers, model_type, result, ttl=300)
            safe_log(f"ìºì‹œ ì €ì¥: {model_type} ì˜ˆì¸¡", 'info')
        
        return result
        
    except Exception as e:
        safe_log(f"AI ì˜ˆì¸¡ ìƒì„± ì‹¤íŒ¨: {str(e)}", 'error')
        # ì™„ì „í•œ ëœë¤ ìƒì„±ìœ¼ë¡œ í´ë°±
        return sorted(random.sample(range(1, 46), 6))

# ===== API ì—”ë“œí¬ì¸íŠ¸ë“¤ =====
@app.route('/')
def index():
    try:
        context = {
            'update_date': '2025.08.28',
            'analysis_round': 1186,
            'copyright_year': 2025,
            'version': 'v2.1',
            'features_count': 15,
            'models_count': len(AI_MODELS_INFO),
            'monitoring_enabled': MONITORING_AVAILABLE,
            'cache_enabled': CACHE_AVAILABLE
        }
        return render_template('index.html', **context)
    except Exception as e:
        safe_log(f"ë©”ì¸ í˜ì´ì§€ ì˜¤ë¥˜: {str(e)}", 'error')
        return render_template('error.html', 
            error_message="ì„œë¹„ìŠ¤ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.",
            error_id=str(uuid.uuid4())[:8]
        ), 503

@app.route('/api/predict', methods=['POST'])
@monitor_performance if MONITORING_AVAILABLE else lambda f: f  # ğŸ†• ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
@rate_limiter(max_requests=30, time_window=3600)  # ì‹œê°„ë‹¹ 30íšŒ ì œí•œ
@timeout_handler(timeout_seconds=15)
def predict():
    try:
        # ìš”ì²­ ë°ì´í„° ê²€ì¦
        data = request.get_json() or {}
        user_numbers = data.get('user_numbers', [])
        
        # ë²ˆí˜¸ ìœ íš¨ì„± ê²€ì‚¬
        is_valid, message = validate_lotto_numbers(user_numbers)
        if not is_valid:
            return jsonify({
                'success': False,
                'error': True,
                'message': message,
                'error_type': 'validation'
            }), 400
        
        # ğŸ†• ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼ ìºì‹œ í™•ì¸
        if CACHE_AVAILABLE and cache_manager:
            user_hash = hashlib.md5(json.dumps(sorted(user_numbers)).encode()).hexdigest()[:8]
            cache_key = f"full_prediction:{user_hash}"
            cached_full_result = cache_manager.get(cache_key)
            
            if cached_full_result:
                safe_log("ì „ì²´ ì˜ˆì¸¡ ìºì‹œ íˆíŠ¸", 'info')
                cached_full_result['cached'] = True
                cached_full_result['cache_hit_time'] = time.time()
                return jsonify(cached_full_result)
        
        # AI ëª¨ë¸ ì˜ˆì¸¡
        models = {}
        model_configs = [
            ('ë¹ˆë„ë¶„ì„ ëª¨ë¸', 'frequency'),
            ('íŠ¸ë Œë“œë¶„ì„ ëª¨ë¸', 'trend'),
            ('íŒ¨í„´ë¶„ì„ ëª¨ë¸', 'pattern'),
            ('í†µê³„ë¶„ì„ ëª¨ë¸', 'statistical'),
            ('ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸', 'ml')
        ]
        
        prediction_start_time = time.time()
        
        for model_name, model_type in model_configs:
            try:
                predictions = []
                for i in range(5):
                    pred = generate_ai_prediction(user_numbers, model_type)
                    predictions.append(pred)
                
                model_info = AI_MODELS_INFO.get(model_type, {})
                models[model_name] = {
                    'description': model_info.get('description', ''),
                    'predictions': predictions,
                    'accuracy': model_info.get('accuracy_rate', 15),
                    'confidence': random.randint(85, 95),
                    'algorithm': model_info.get('algorithm', 'N/A')
                }
            except Exception as e:
                safe_log(f"Model {model_name} prediction failed: {str(e)}", 'warning')
                # ê°œë³„ ëª¨ë¸ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì œê³µ
                models[model_name] = {
                    'description': 'ì¼ì‹œì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                    'predictions': [sorted(random.sample(range(1, 46), 6)) for _ in range(5)],
                    'accuracy': 15,
                    'confidence': 70,
                    'algorithm': 'Fallback',
                    'error': True
                }
        
        # TOP ì¶”ì²œ ë²ˆí˜¸ ìƒì„±
        top_recommendations = []
        for i in range(5):
            rec = generate_ai_prediction(user_numbers, "statistical")
            if rec not in top_recommendations:
                top_recommendations.append(rec)
        
        prediction_time = time.time() - prediction_start_time
        
        response = {
            'success': True,
            'user_numbers': user_numbers,
            'models': models,
            'top_recommendations': top_recommendations,
            'total_combinations': sum(len(model.get('predictions', [])) for model in models.values()),
            'data_source': f"{len(sample_data)}íšŒì°¨ ë°ì´í„°" if sample_data else "ìƒ˜í”Œ ë°ì´í„°",
            'analysis_timestamp': datetime.now().isoformat(),
            'processing_time': round(prediction_time, 3),
            'version': '2.1',
            'request_id': str(uuid.uuid4())[:8],
            'cached': False,
            'cache_info': {
                'enabled': CACHE_AVAILABLE,
                'hit_rate': cache_manager.stats.hit_rate if CACHE_AVAILABLE and cache_manager else 0
            }
        }
        
        # ğŸ†• ì „ì²´ ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥ (5ë¶„)
        if CACHE_AVAILABLE and cache_manager:
            user_hash = hashlib.md5(json.dumps(sorted(user_numbers)).encode()).hexdigest()[:8]
            cache_key = f"full_prediction:{user_hash}"
            cache_manager.set(cache_key, response, ttl=300, tags=['predictions', 'full_results'])
            safe_log("ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼ ìºì‹œ ì €ì¥", 'info')
        
        return jsonify(response)
        
    except Exception as e:
        safe_log(f"ì˜ˆì¸¡ API ì‹¤íŒ¨: {str(e)}", 'error')
        return handle_api_error(e)

@app.route('/api/stats')
@monitor_performance if MONITORING_AVAILABLE else lambda f: f  # ğŸ†• ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
@timeout_handler(timeout_seconds=10)
def get_stats():
    try:
        # ğŸ†• ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
        if CACHE_AVAILABLE and cache_manager:
            cached_stats = cache_manager.get_cached_statistics('main')
            if cached_stats:
                return jsonify({
                    'success': True,
                    'cached': True,
                    'cache_timestamp': time.time(),
                    **cached_stats
                })
        
        frequency = calculate_frequency_analysis()
        
        if frequency:
            sorted_freq = sorted(frequency.items(), key=lambda x: x[1], reverse=True)
            hot_numbers = sorted_freq[:8]
            cold_numbers = sorted_freq[-8:]
        else:
            # ê¸°ë³¸ê°’ ì œê³µ
            hot_numbers = [[7, 15], [13, 14], [22, 13], [31, 12], [42, 11], [1, 10], [25, 9], [33, 8]]
            cold_numbers = [[45, 5], [44, 6], [43, 7], [2, 8], [3, 9], [4, 10], [5, 11], [6, 12]]
        
        stats_data = {
            'frequency': frequency,
            'hot_numbers': hot_numbers,
            'cold_numbers': cold_numbers,
            'carry_over_analysis': calculate_carry_over_analysis(),
            'companion_analysis': list(calculate_companion_analysis().items()),
            'pattern_analysis': calculate_pattern_analysis(),
            'total_draws': len(sample_data) if sample_data else 200,
            'data_source': f"{len(sample_data)}íšŒì°¨ ë°ì´í„°" if sample_data else "ìƒ˜í”Œ ë°ì´í„°",
            'last_updated': datetime.now().isoformat(),
            'cache_status': 'fresh'
        }
        
        # ğŸ†• ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥ (10ë¶„)
        if CACHE_AVAILABLE and cache_manager:
            cache_manager.cache_statistics('main', stats_data, ttl=600)
            safe_log("í†µê³„ ë°ì´í„° ìºì‹œ ì €ì¥", 'info')
        
        return jsonify({
            'success': True,
            'cached': False,
            **stats_data
        })
        
    except Exception as e:
        safe_log(f"í†µê³„ API ì‹¤íŒ¨: {str(e)}", 'error')
        return handle_api_error(e)

# ğŸ”§ ì´ˆê°„ë‹¨ health_check í•¨ìˆ˜ (ëª¨ë“  ë³µì¡í•œ ê¸°ëŠ¥ ì œê±°)
@app.route('/api/health')
def health_check():
    """ì´ˆê°„ë‹¨ health check - ëª¨ë“  ë³µì¡í•œ ê¸°ëŠ¥ ì œê±°"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'version': '2.1',
        'message': 'OK'
    })

def initialize_app():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ˆê¸°í™” (ê°„ì†Œí™”ëœ ë²„ì „)"""
    global sample_data, monitor, cache_manager
    try:
        safe_log("=== ğŸš€ LottoPro-AI v2.1 ì´ˆê¸°í™” ì‹œì‘ ===")
        
        # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
        sample_data = generate_sample_data()
        safe_log(f"âœ… ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(sample_data)}íšŒì°¨")
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì´ˆê¸°í™”
        performance_metrics['start_time'] = datetime.now()
        
        # ğŸ†• ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        if MONITORING_AVAILABLE:
            try:
                monitor = init_monitoring(
                    app=app, 
                    auto_start=True,
                    custom_thresholds={
                        'response_time': 10.0,    # 10ì´ˆ
                        'error_rate': 0.05,       # 5%
                        'cpu_usage': 80.0,        # 80%
                        'memory_usage': 85.0      # 85%
                    }
                )
                app.monitor = monitor
                safe_log("âœ… ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ í™œì„±í™” ì™„ë£Œ")
                
            except Exception as e:
                safe_log(f"âŒ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}", 'error')
        
        # ğŸ†• ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” (í•µì‹¬ ìˆ˜ì • ë¶€ë¶„)
        if CACHE_AVAILABLE:
            try:
                cache_manager = init_cache_system(
                    app=app,
                    redis_url=os.getenv('REDIS_URL'),  # í™˜ê²½ë³€ìˆ˜ì—ì„œ Redis URL
                    default_ttl=300,  # 5ë¶„ ê¸°ë³¸ TTL
                    memory_cache_size=1000,
                    enable_compression=True,
                    enable_warming=os.getenv('CACHE_WARMING', 'true').lower() == 'true'  # ğŸ”§ í•µì‹¬ ìˆ˜ì •!
                )
                app.cache = cache_manager
                safe_log("âœ… ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
                
            except Exception as e:
                safe_log(f"âŒ ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}", 'error')
        
        safe_log(f"âœ… 15ê°€ì§€ ê¸°ëŠ¥ ë¡œë“œ ì™„ë£Œ")
        safe_log(f"âœ… AI ëª¨ë¸ {len(AI_MODELS_INFO)}ê°œ ì¤€ë¹„ ì™„ë£Œ")
        safe_log(f"âœ… íŒë§¤ì  ë°ì´í„° {len(LOTTERY_STORES)}ê°œ ë¡œë“œ ì™„ë£Œ")
        safe_log("âœ… íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬ ë° ì—ëŸ¬ í•¸ë“¤ë§ ì‹œìŠ¤í…œ í™œì„±í™”")
        safe_log("=== ğŸ‰ ì´ˆê¸°í™” ì™„ë£Œ ===")
        
    except Exception as e:
        safe_log(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}", 'error')
        # ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œì—ë„ ê¸°ë³¸ ì„œë¹„ìŠ¤ëŠ” ì œê³µ
        if not sample_data:
            sample_data = []

if __name__ == '__main__':
    initialize_app()
    
    port = int(os.environ.get('PORT', 5000))
    debug_mode = os.environ.get('DEBUG', 'False').lower() == 'true'
    
    safe_log(f"ğŸš€ ì„œë²„ ì‹œì‘ - í¬íŠ¸: {port}, ë””ë²„ê·¸ ëª¨ë“œ: {debug_mode}")
    safe_log("=== ğŸ¯ LottoPro AI v2.1 - ì•ˆì •í™” ë²„ì „ ===")
    
    app.run(debug=debug_mode, host='0.0.0.0', port=port)
else:
    initialize_app()
